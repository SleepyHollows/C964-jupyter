{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1f769be",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Theme Park Reviews\n",
    "Author: Caleb Hathaway"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e06289b",
   "metadata": {},
   "source": [
    "\n",
    "Importing all libraries needed for program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6037577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from ipywidgets import HBox, Label, Layout\n",
    "import ipywidgets as widgets\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4fe8bb",
   "metadata": {},
   "source": [
    "\n",
    "Initiating the Sentiment Analysis Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa4a360",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f325806",
   "metadata": {},
   "source": [
    "\n",
    "Picking a park to see reviews for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9cd7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parkOption = widgets.Select(\n",
    "    options = ['Disney', 'Universal'],\n",
    "    value = 'Disney',\n",
    "    # rows = 10,\n",
    "    description = 'Park:',\n",
    "    disabled = False\n",
    ")\n",
    "parkOption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7e8f00",
   "metadata": {},
   "source": [
    "\n",
    "Assigning the park dataset to whichever park is picked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4501b580",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(parkOption.value == 'Disney'):\n",
    "    parkData = pd.read_csv('DisneylandReviews.csv')\n",
    "elif(parkOption.value == 'Universal'):\n",
    "    parkData = pd.read_csv('UniversalReviews.csv')\n",
    "parkData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4039a3",
   "metadata": {},
   "source": [
    "\n",
    "Asigning terms for cleaning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891585ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm',disable = ['parser','ner'])\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a53ac5",
   "metadata": {},
   "source": [
    "\n",
    "All methods that will be used to visualize the data and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5d7c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def barChart_generator(data, title = None):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,1,2,3])\n",
    "    x = [0, 10, 20, 30, 40, 50, 60, 70, 80]\n",
    "    sentimentsTitle = ['Positive', 'Negative']\n",
    "    pos = data['positive']\n",
    "    neg = data['negative']\n",
    "    sentimentValues = [pos, neg]\n",
    "    ax.bar(sentimentsTitle, sentimentValues)\n",
    "    plt.yticks(np.arange(min(x), max(x), 5.0))\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1362d3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pieChart_generator(scores, title = None):\n",
    "    labels = ['positive', 'negative', 'neutral']\n",
    "    sizes = [scores[0], scores[1], scores[2]]\n",
    "    plt.pie(sizes, labels=labels, autopct='%1.1f%%')\n",
    "    plt.axis('equal')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ee265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordCloud_generator(data, title = None):\n",
    "    data_cleaned = cleaning(data)\n",
    "    wordcloud = WordCloud(width = 800, height = 800,\n",
    "                          background_color ='black',\n",
    "                          min_font_size = 10\n",
    "                         ).generate(\" \".join(data_cleaned.values))                      \n",
    "    plt.figure(figsize = (8, 8), facecolor = None) \n",
    "    plt.imshow(wordcloud, interpolation='bilinear') \n",
    "    plt.axis(\"off\") \n",
    "    plt.tight_layout(pad = 0) \n",
    "    plt.title(title,fontsize=30)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07d4329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(text, stem = \"None\"):\n",
    "    final_string = \"\"\n",
    "    # Make lower\n",
    "    text = text.lower()\n",
    "    # Remove line breaks\n",
    "    text = re.sub(r'\\n', '', text)\n",
    "    # Remove puncuation\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(translator)\n",
    "    # Remove stop words\n",
    "    text = text.split()\n",
    "    useless_words = nltk.corpus.stopwords.words(\"english\")\n",
    "    useless_words = useless_words + ['hi', 'im', 'go', 'we', 'unless', 'back', 'lot']\n",
    "    text_filtered = [word for word in text if not word in useless_words]\n",
    "    # Remove numbers\n",
    "    text_filtered = [re.sub(r'\\w*\\d\\w*', '', w) for w in text_filtered]\n",
    "    # Stem or Lemmatize\n",
    "    if stem == 'Stem':\n",
    "        stemmer = PorterStemmer() \n",
    "        text_stemmed = [stemmer.stem(y) for y in text_filtered]\n",
    "    elif stem == 'Lem':\n",
    "        lem = WordNetLemmatizer()\n",
    "        text_stemmed = [lem.lemmatize(y) for y in text_filtered]\n",
    "    elif stem == 'Spacy':\n",
    "        text_filtered = nlp(' '.join(text_filtered))\n",
    "        text_stemmed = [y.lemma_ for y in text_filtered]\n",
    "    else:\n",
    "        text_stemmed = text_filtered\n",
    "    final_string = ' '.join(text_stemmed)\n",
    "    return final_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f13626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(reviews):\n",
    "    nlp = spacy.load('en_core_web_sm',disable = ['parser','ner'])\n",
    "    stop = stopwords.words('english')\n",
    "    all_=[]\n",
    "    for review in reviews:\n",
    "        lower_case = review.lower() #lower case the text\n",
    "        lower_case = lower_case.replace(\" n't\",\" not\") #correct n't as not\n",
    "        lower_case = lower_case.replace(\".\",\" . \")\n",
    "        lower_case = ' '.join(word.strip(string.punctuation) for word \n",
    "                              in lower_case.split()) #remove punctuation\n",
    "        words = lower_case.split() #split into words\n",
    "        words = [word for word in words if word.isalpha()] #remove numbers\n",
    "        split = [word for word in words if word not in stop] #remove stop words\n",
    "        reformed = \" \".join(split) #join words back to the text\n",
    "        doc = nlp(reformed)\n",
    "        reformed = \" \".join([token.lemma_ for token in doc]) #lemmatiztion\n",
    "        all_.append(reformed)\n",
    "    data_cleaned = pd.DataFrame()\n",
    "    data_cleaned['clean_reviews'] = all_\n",
    "    return data_cleaned['clean_reviews']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d678a0c8",
   "metadata": {},
   "source": [
    "\n",
    "Pick a year for the subset of data to be parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a36cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearOption = widgets.Select(\n",
    "    options = ['2016', '2017', '2018', '2019'],\n",
    "    value = '2016',\n",
    "    # rows = 10,\n",
    "    description = 'Year:',\n",
    "    disabled = False\n",
    ")\n",
    "yearOption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45d2d71",
   "metadata": {},
   "source": [
    "\n",
    "Pick a year for the subset of data to be parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5293575",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthOption = widgets.Select(\n",
    "    options = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12'],\n",
    "    value = '1',\n",
    "    # rows = 10,\n",
    "    description = 'Month:',\n",
    "    disabled = False\n",
    ")\n",
    "monthOption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a77d756",
   "metadata": {},
   "source": [
    "\n",
    "Using the selected Year and Month to pull the subset of data that will be analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf659a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedData = parkData[parkData['Date'] == yearOption.value + '-' + monthOption.value]['Review']\n",
    "selectedData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dfb7e2",
   "metadata": {},
   "source": [
    "\n",
    "Parsing data for data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1385fc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearSelection = parkData.loc[parkData[\"Date\"].between(yearOption.value + \"-1\", yearOption.value + '-12')][\"Review\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a055b6c6",
   "metadata": {},
   "source": [
    "\n",
    "Displaying reviews to pick, the review picked can be ran through the sentiment analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc84137",
   "metadata": {},
   "outputs": [],
   "source": [
    "style = {'description_width': 'initial'}\n",
    "reviewOption = widgets.Select(\n",
    "    options = [selectedData[0], selectedData[1], selectedData[2], selectedData[3], selectedData[4], selectedData[5], selectedData[6], selectedData[7], selectedData[8], selectedData[9], selectedData[10], selectedData[11], selectedData[12], selectedData[13], selectedData[14], selectedData[15], selectedData[16], selectedData[17]],\n",
    "    # rows = 18,\n",
    "    description = 'Review:',\n",
    "    disabled = False,\n",
    "    layout = Layout(width = '100%', height = '100px')\n",
    ")\n",
    "reviewOption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c81d2f3",
   "metadata": {},
   "source": [
    "\n",
    "Cleaning the selected review using the clean_string() def before it is put through the senetiment analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ff50b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = clean_string(reviewOption.value)\n",
    "if (sia.polarity_scores(cleaned)['compound'] > 0):\n",
    "    print(\"This review's sentiment is Positive\")\n",
    "else:\n",
    "    print(\"This review's sentiment is Negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cada0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "positiveReview = 0\n",
    "negativeReview = 0\n",
    "values = dict()\n",
    "cleaned = cleaning(yearSelection)\n",
    "for review in cleaned:\n",
    "    if (sia.polarity_scores(review)['compound'] > 0):\n",
    "        positiveReview += 1\n",
    "    else:\n",
    "        negativeReview += 1\n",
    "values['positive'] = positiveReview\n",
    "values['negative'] = negativeReview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af247e2c",
   "metadata": {},
   "source": [
    "\n",
    "Displaying the number of positive and negative reviews that the sentiment analysis model has detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9171eac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "barChart_generator(values, \"Review Sentiment for year selected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a97c8e1",
   "metadata": {},
   "source": [
    "\n",
    "Pulling, cleaning, running the reviews through the sentiment model then appending each value to an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b5e4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "posavg = 0\n",
    "negavg = 0\n",
    "nueavg = 0\n",
    "pos = []\n",
    "neg = []\n",
    "nue = []\n",
    "scores = []\n",
    "cleaned = cleaning(yearSelection)\n",
    "\n",
    "for review in cleaned:\n",
    "    sentiment = sia.polarity_scores(review)['pos']\n",
    "    pos.append(sentiment)\n",
    "    \n",
    "for review in cleaned:    \n",
    "    sentiment = sia.polarity_scores(review)['neg']\n",
    "    neg.append(sentiment)\n",
    "    \n",
    "for review in cleaned:    \n",
    "    sentiment = sia.polarity_scores(review)['neu']\n",
    "    nue.append(sentiment)\n",
    "\n",
    "    \n",
    "for val in pos:\n",
    "    posavg += val\n",
    "    \n",
    "for val in neg:\n",
    "    negavg += val\n",
    "    \n",
    "for val in nue:\n",
    "    nueavg += val\n",
    "\n",
    "posavg = posavg / len(pos)\n",
    "negavg = negavg / len(neg)\n",
    "nueavg = nueavg / len(nue)\n",
    "\n",
    "scores.append(posavg)\n",
    "scores.append(negavg)\n",
    "scores.append(nueavg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6f214e",
   "metadata": {},
   "source": [
    "\n",
    "Using pulled scores and displaying the average of the overall sentiment values for the year selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2696350d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pieChart_generator(scores, \"Overall sentiment of year picked\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89da1c2",
   "metadata": {},
   "source": [
    "\n",
    "Pulling all the reviews for the selected month, year, park and making a display the most used words for that time period \n",
    "and park"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14ec8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCloud_generator(selectedData, \"Most popular words in reviews\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
