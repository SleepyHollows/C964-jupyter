{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1f769be",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Theme Park Reviews\n",
    "Author: Caleb Hathaway"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e06289b",
   "metadata": {},
   "source": [
    "\n",
    "Importing all libraries needed for program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6037577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from ipywidgets import HBox, Label, Layout\n",
    "import ipywidgets as widgets\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7861ee0",
   "metadata": {},
   "source": [
    "\n",
    "Installing vader lexison for sentiment anaylsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21f1968b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\hatha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4fe8bb",
   "metadata": {},
   "source": [
    "\n",
    "Initiating the Sentiment Analysis Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aa4a360",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f325806",
   "metadata": {},
   "source": [
    "\n",
    "Picking a park to see reviews for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba9cd7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17dce02add014485ae53bc0e85ddd276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Select(description='Park:', options=('Disney', 'Universal'), value='Disney')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parkOption = widgets.Select(\n",
    "    options = ['Disney', 'Universal'],\n",
    "    value = 'Disney',\n",
    "    # rows = 10,\n",
    "    description = 'Park:',\n",
    "    disabled = False\n",
    ")\n",
    "parkOption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7e8f00",
   "metadata": {},
   "source": [
    "\n",
    "Assigning the park dataset to whichever park is picked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4501b580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1564</td>\n",
       "      <td>2016-1</td>\n",
       "      <td>Ok, this one will be a short one. You want to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1565</td>\n",
       "      <td>2016-1</td>\n",
       "      <td>We loved visiting Disneyland! I went there wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1566</td>\n",
       "      <td>2016-1</td>\n",
       "      <td>We spent only a day at Disneyland, due to time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1567</td>\n",
       "      <td>2016-1</td>\n",
       "      <td>Pricing of Hong Kong Disneyland from 16 Decemb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1568</td>\n",
       "      <td>2016-1</td>\n",
       "      <td>Avoid rush, reach early and directly go to the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>2543</td>\n",
       "      <td>2019-12</td>\n",
       "      <td>I always walk through Disneyland worry free an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>2544</td>\n",
       "      <td>2019-12</td>\n",
       "      <td>The holiday time is a great one to go, the par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>2545</td>\n",
       "      <td>2019-12</td>\n",
       "      <td>This theme park is amazing, all rides are amaz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>2546</td>\n",
       "      <td>2019-12</td>\n",
       "      <td>I've been to Disneyland every single year at l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>2547</td>\n",
       "      <td>2019-12</td>\n",
       "      <td>This was our first trip to Disneyland. Since w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>984 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID     Date                                             Review\n",
       "0    1564   2016-1  Ok, this one will be a short one. You want to ...\n",
       "1    1565   2016-1  We loved visiting Disneyland! I went there wit...\n",
       "2    1566   2016-1  We spent only a day at Disneyland, due to time...\n",
       "3    1567   2016-1  Pricing of Hong Kong Disneyland from 16 Decemb...\n",
       "4    1568   2016-1  Avoid rush, reach early and directly go to the...\n",
       "..    ...      ...                                                ...\n",
       "979  2543  2019-12  I always walk through Disneyland worry free an...\n",
       "980  2544  2019-12  The holiday time is a great one to go, the par...\n",
       "981  2545  2019-12  This theme park is amazing, all rides are amaz...\n",
       "982  2546  2019-12  I've been to Disneyland every single year at l...\n",
       "983  2547  2019-12  This was our first trip to Disneyland. Since w...\n",
       "\n",
       "[984 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if(parkOption.value == 'Disney'):\n",
    "    parkData = pd.read_csv('DisneylandReviews.csv')\n",
    "elif(parkOption.value == 'Universal'):\n",
    "    parkData = pd.read_csv('UniversalReviews.csv')\n",
    "parkData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4039a3",
   "metadata": {},
   "source": [
    "\n",
    "Asigning terms for cleaning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "891585ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable = ['parser','ner'])\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a53ac5",
   "metadata": {},
   "source": [
    "\n",
    "All methods that will be used to visualize the data and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5d7c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def barChart_generator(data, title = None):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,1,2,3])\n",
    "    x = [0, 10, 20, 30, 40, 50, 60, 70, 80]\n",
    "    sentimentsTitle = ['Positive', 'Negative']\n",
    "    pos = data['positive']\n",
    "    neg = data['negative']\n",
    "    sentimentValues = [pos, neg]\n",
    "    ax.bar(sentimentsTitle, sentimentValues)\n",
    "    plt.yticks(np.arange(min(x), max(x), 5.0))\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1362d3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pieChart_generator(scores, title = None):\n",
    "    labels = ['positive', 'negative', 'neutral']\n",
    "    sizes = [scores[0], scores[1], scores[2]]\n",
    "    plt.pie(sizes, labels=labels, autopct='%1.1f%%')\n",
    "    plt.axis('equal')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ee265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordCloud_generator(data, title = None):\n",
    "    data_cleaned = cleaning(data)\n",
    "    wordcloud = WordCloud(width = 800, height = 800,\n",
    "                          background_color ='black',\n",
    "                          min_font_size = 10\n",
    "                         ).generate(\" \".join(data_cleaned.values))                      \n",
    "    plt.figure(figsize = (8, 8), facecolor = None) \n",
    "    plt.imshow(wordcloud, interpolation='bilinear') \n",
    "    plt.axis(\"off\") \n",
    "    plt.tight_layout(pad = 0) \n",
    "    plt.title(title,fontsize=30)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07d4329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(text, stem = \"None\"):\n",
    "    final_string = \"\"\n",
    "    # Make lower\n",
    "    text = text.lower()\n",
    "    # Remove line breaks\n",
    "    text = re.sub(r'\\n', '', text)\n",
    "    # Remove puncuation\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(translator)\n",
    "    # Remove stop words\n",
    "    text = text.split()\n",
    "    useless_words = nltk.corpus.stopwords.words(\"english\")\n",
    "    useless_words = useless_words + ['hi', 'im', 'go', 'we', 'unless', 'back', 'lot']\n",
    "    text_filtered = [word for word in text if not word in useless_words]\n",
    "    # Remove numbers\n",
    "    text_filtered = [re.sub(r'\\w*\\d\\w*', '', w) for w in text_filtered]\n",
    "    # Stem or Lemmatize\n",
    "    if stem == 'Stem':\n",
    "        stemmer = PorterStemmer() \n",
    "        text_stemmed = [stemmer.stem(y) for y in text_filtered]\n",
    "    elif stem == 'Lem':\n",
    "        lem = WordNetLemmatizer()\n",
    "        text_stemmed = [lem.lemmatize(y) for y in text_filtered]\n",
    "    elif stem == 'Spacy':\n",
    "        text_filtered = nlp(' '.join(text_filtered))\n",
    "        text_stemmed = [y.lemma_ for y in text_filtered]\n",
    "    else:\n",
    "        text_stemmed = text_filtered\n",
    "    final_string = ' '.join(text_stemmed)\n",
    "    return final_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f13626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(reviews):\n",
    "    nlp = spacy.load('en_core_web_sm',disable = ['parser','ner'])\n",
    "    stop = stopwords.words('english')\n",
    "    all_=[]\n",
    "    for review in reviews:\n",
    "        lower_case = review.lower() #lower case the text\n",
    "        lower_case = lower_case.replace(\" n't\",\" not\") #correct n't as not\n",
    "        lower_case = lower_case.replace(\".\",\" . \")\n",
    "        lower_case = ' '.join(word.strip(string.punctuation) for word \n",
    "                              in lower_case.split()) #remove punctuation\n",
    "        words = lower_case.split() #split into words\n",
    "        words = [word for word in words if word.isalpha()] #remove numbers\n",
    "        split = [word for word in words if word not in stop] #remove stop words\n",
    "        reformed = \" \".join(split) #join words back to the text\n",
    "        doc = nlp(reformed)\n",
    "        reformed = \" \".join([token.lemma_ for token in doc]) #lemmatiztion\n",
    "        all_.append(reformed)\n",
    "    data_cleaned = pd.DataFrame()\n",
    "    data_cleaned['clean_reviews'] = all_\n",
    "    return data_cleaned['clean_reviews']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d678a0c8",
   "metadata": {},
   "source": [
    "\n",
    "Pick a year for the subset of data to be parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a36cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearOption = widgets.Select(\n",
    "    options = ['2016', '2017', '2018', '2019'],\n",
    "    value = '2016',\n",
    "    # rows = 10,\n",
    "    description = 'Year:',\n",
    "    disabled = False\n",
    ")\n",
    "yearOption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45d2d71",
   "metadata": {},
   "source": [
    "\n",
    "Pick a year for the subset of data to be parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5293575",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthOption = widgets.Select(\n",
    "    options = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12'],\n",
    "    value = '1',\n",
    "    # rows = 10,\n",
    "    description = 'Month:',\n",
    "    disabled = False\n",
    ")\n",
    "monthOption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a77d756",
   "metadata": {},
   "source": [
    "\n",
    "Using the selected Year and Month to pull the subset of data that will be analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf659a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedData = parkData[parkData['Date'] == yearOption.value + '-' + monthOption.value]['Review']\n",
    "selectedData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dfb7e2",
   "metadata": {},
   "source": [
    "\n",
    "Parsing data for data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1385fc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearSelection = parkData.loc[parkData[\"Date\"].between(yearOption.value + \"-1\", yearOption.value + '-12')][\"Review\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a055b6c6",
   "metadata": {},
   "source": [
    "\n",
    "Displaying reviews to pick, the review picked can be ran through the sentiment analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc84137",
   "metadata": {},
   "outputs": [],
   "source": [
    "style = {'description_width': 'initial'}\n",
    "reviewOption = widgets.Select(\n",
    "    options = [selectedData[0], selectedData[1], selectedData[2], selectedData[3], selectedData[4], selectedData[5], selectedData[6], selectedData[7], selectedData[8], selectedData[9], selectedData[10], selectedData[11], selectedData[12], selectedData[13], selectedData[14], selectedData[15], selectedData[16], selectedData[17]],\n",
    "    # rows = 18,\n",
    "    description = 'Review:',\n",
    "    disabled = False,\n",
    "    layout = Layout(width = '100%', height = '100px')\n",
    ")\n",
    "reviewOption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c81d2f3",
   "metadata": {},
   "source": [
    "\n",
    "Cleaning the selected review using the clean_string() def before it is put through the senetiment analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ff50b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = clean_string(reviewOption.value)\n",
    "if (sia.polarity_scores(cleaned)['compound'] > 0):\n",
    "    print(\"This review's sentiment is Positive\")\n",
    "else:\n",
    "    print(\"This review's sentiment is Negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cada0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "positiveReview = 0\n",
    "negativeReview = 0\n",
    "values = dict()\n",
    "cleaned = cleaning(yearSelection)\n",
    "for review in cleaned:\n",
    "    if (sia.polarity_scores(review)['compound'] > 0):\n",
    "        positiveReview += 1\n",
    "    else:\n",
    "        negativeReview += 1\n",
    "values['positive'] = positiveReview\n",
    "values['negative'] = negativeReview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af247e2c",
   "metadata": {},
   "source": [
    "\n",
    "Displaying the number of positive and negative reviews that the sentiment analysis model has detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9171eac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "barChart_generator(values, \"Review Sentiment for year selected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a97c8e1",
   "metadata": {},
   "source": [
    "\n",
    "Pulling, cleaning, running the reviews through the sentiment model then appending each value to an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b5e4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "posavg = 0\n",
    "negavg = 0\n",
    "nueavg = 0\n",
    "pos = []\n",
    "neg = []\n",
    "nue = []\n",
    "scores = []\n",
    "cleaned = cleaning(yearSelection)\n",
    "\n",
    "for review in cleaned:\n",
    "    sentiment = sia.polarity_scores(review)['pos']\n",
    "    pos.append(sentiment)\n",
    "    \n",
    "for review in cleaned:    \n",
    "    sentiment = sia.polarity_scores(review)['neg']\n",
    "    neg.append(sentiment)\n",
    "    \n",
    "for review in cleaned:    \n",
    "    sentiment = sia.polarity_scores(review)['neu']\n",
    "    nue.append(sentiment)\n",
    "\n",
    "    \n",
    "for val in pos:\n",
    "    posavg += val\n",
    "    \n",
    "for val in neg:\n",
    "    negavg += val\n",
    "    \n",
    "for val in nue:\n",
    "    nueavg += val\n",
    "\n",
    "posavg = posavg / len(pos)\n",
    "negavg = negavg / len(neg)\n",
    "nueavg = nueavg / len(nue)\n",
    "\n",
    "scores.append(posavg)\n",
    "scores.append(negavg)\n",
    "scores.append(nueavg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6f214e",
   "metadata": {},
   "source": [
    "\n",
    "Using pulled scores and displaying the average of the overall sentiment values for the year selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2696350d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pieChart_generator(scores, \"Overall sentiment of year picked\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89da1c2",
   "metadata": {},
   "source": [
    "\n",
    "Pulling all the reviews for the selected month, year, park and making a display the most used words for that time period \n",
    "and park"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14ec8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCloud_generator(selectedData, \"Most popular words in reviews\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
